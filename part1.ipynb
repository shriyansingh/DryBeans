{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in xlsx dataset from folder called DryBeanDataSet.xlsx\n",
    "df = pd.read_excel('DryBeanDataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_stats(df):\n",
    "    # Replace '?' with NaN\n",
    "    df_clean = df.replace('?', np.nan)\n",
    "    \n",
    "    stats_df = pd.DataFrame({\n",
    "        'Data Type': df_clean.dtypes,\n",
    "        'Non-Null Count': df_clean.count(),\n",
    "        'Null Count': df_clean.isnull().sum(),\n",
    "        'Null Percentage': (df_clean.isnull().sum() / len(df_clean)) * 100,\n",
    "        'Unique Values': df_clean.nunique(),\n",
    "    })\n",
    "    \n",
    "    # Handle numeric columns separately\n",
    "    numeric_columns = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    stats_df.loc[numeric_columns, 'Min'] = df_clean[numeric_columns].min()\n",
    "    stats_df.loc[numeric_columns, 'Max'] = df_clean[numeric_columns].max()\n",
    "    stats_df.loc[numeric_columns, 'Mean'] = df_clean[numeric_columns].mean()\n",
    "    stats_df.loc[numeric_columns, 'Median'] = df_clean[numeric_columns].median()\n",
    "    stats_df.loc[numeric_columns, 'Std Dev'] = df_clean[numeric_columns].std()\n",
    "    stats_df.loc[numeric_columns, 'Skewness'] = df_clean[numeric_columns].skew()\n",
    "    stats_df.loc[numeric_columns, 'Kurtosis'] = df_clean[numeric_columns].kurtosis()\n",
    "    \n",
    "    # Handle mode separately as it can be applied to both numeric and categorical data\n",
    "    stats_df['Mode'] = df_clean.mode().iloc[0]\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "# Use the updated function\n",
    "feature_stats = get_feature_stats(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_numerical_features(df, numerical_columns=None, features_per_plot=9, exclude_features=None, figsize=(20, 5)):\n",
    "    if exclude_features is None:\n",
    "        exclude_features = []\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    else:\n",
    "        numerical_columns = [col for col in numerical_columns if col in df.columns]\n",
    "    \n",
    "    numerical_features = [f for f in numerical_columns if f not in exclude_features]\n",
    "    \n",
    "    n_features = len(numerical_features)\n",
    "    n_plots = (n_features - 1) // features_per_plot + 1\n",
    "    \n",
    "    for plot_num in range(n_plots):\n",
    "        start_idx = plot_num * features_per_plot\n",
    "        end_idx = min((plot_num + 1) * features_per_plot, n_features)\n",
    "        plot_features = numerical_features[start_idx:end_idx]\n",
    "        \n",
    "        n_cols = 3\n",
    "        n_rows = (len(plot_features) - 1) // n_cols + 1\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(figsize[0], figsize[1]*n_rows))\n",
    "        fig.suptitle(f'Distribution of Numerical Features (Part {plot_num + 1})', fontsize=16)\n",
    "        \n",
    "        axes = axes.flatten() if isinstance(axes, np.ndarray) else [axes]\n",
    "        \n",
    "        for i, feature in enumerate(plot_features):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Convert to numeric, coercing errors to NaN\n",
    "            series = pd.to_numeric(df[feature], errors='coerce')\n",
    "            \n",
    "            # Plot histogram with KDE\n",
    "            sns.histplot(series.dropna(), kde=True, ax=ax)\n",
    "            ax.set_title(feature)\n",
    "            ax.set_xlabel('')\n",
    "            \n",
    "            # Add text with basic stats\n",
    "            stats_text = f\"Mean: {series.mean():.2f}\\nStd: {series.std():.2f}\\n\"\n",
    "            stats_text += f\"Min: {series.min():.2f}\\nMax: {series.max():.2f}\"\n",
    "            ax.text(0.95, 0.95, stats_text, transform=ax.transAxes, \n",
    "                    verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Remove empty subplots\n",
    "        for i in range(len(plot_features), len(axes)):\n",
    "            fig.delaxes(axes[i])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage:\n",
    "numerical_columns = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', \n",
    "                     'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', \n",
    "                     'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', \n",
    "                     'ShapeFactor4', 'ShapeFactor5', 'ShapeFactor6', 'Sort order']\n",
    "\n",
    "plot_numerical_features(df, numerical_columns=numerical_columns, features_per_plot=9, \n",
    "                        exclude_features=['EquivDiameter'], figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_features(df, categorical_columns=None, max_categories=10, figsize=(12, 5)):\n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    else:\n",
    "        categorical_columns = [col for col in categorical_columns if col in df.columns]\n",
    "    \n",
    "    n_features = len(categorical_columns)\n",
    "\n",
    "    fig, axes = plt.subplots(n_features, 1, figsize=(figsize[0], figsize[1] * n_features))\n",
    "    fig.suptitle('Distribution of Categorical Features', fontsize=16)\n",
    "\n",
    "    if n_features == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, feature in enumerate(categorical_columns):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Get value counts and limit to top categories\n",
    "        value_counts = df[feature].value_counts()\n",
    "        top_categories = value_counts.nlargest(max_categories)\n",
    "        \n",
    "        # Plot top categories\n",
    "        sns.barplot(x=top_categories.values, y=top_categories.index, ax=ax, orient='h')\n",
    "        \n",
    "        # Add count and percentage to labels\n",
    "        total = len(df[feature].dropna())\n",
    "        for j, (name, count) in enumerate(top_categories.items()):\n",
    "            percentage = count / total * 100\n",
    "            ax.text(count, j, f' {count} ({percentage:.1f}%)', va='center')\n",
    "        \n",
    "        ax.set_title(feature)\n",
    "        ax.set_xlabel('Count')\n",
    "\n",
    "        # Add \"Others\" category if necessary\n",
    "        if len(value_counts) > max_categories:\n",
    "            others_count = value_counts.iloc[max_categories:].sum()\n",
    "            others_percentage = others_count / total * 100\n",
    "            ax.text(0, max_categories, f'Others: {others_count} ({others_percentage:.1f}%)', va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "categorical_columns = ['Colour', 'Class']  # Specify the actual categorical columns\n",
    "plot_categorical_features(df, categorical_columns=categorical_columns, max_categories=10, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    corr_matrix = df[numerical_features].corr()\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')\n",
    "    plt.title('Correlation Matrix of Numerical Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_target_variable(df):\n",
    "    print(\"Class Distribution:\")\n",
    "    class_distribution = df['Class'].value_counts(normalize=True) * 100\n",
    "    print(class_distribution)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(y='Class', data=df, order=df['Class'].value_counts().index)\n",
    "    plt.title('Distribution of Bean Classes')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Class')\n",
    "    plt.show()\n",
    "\n",
    "analyze_target_variable(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature Name | Data Type | Range/Unique Values | Central Tendency | Dispersion | Missing Values | Notes |\n",
    "|--------------|-----------|---------------------|-------------------|------------|----------------|-------|\n",
    "| Area | int64 | Min: 20420, Max: 254616 | Mean: 53048.28, Median: 44652 | Std Dev: 29324.10 | Count: 0 | Represents the area of the bean in pixels. Highly skewed (2.95) |\n",
    "| Perimeter | float64 | Min: 524.74, Max: 1985.37 | Mean: 855.28, Median: 794.94 | Std Dev: 214.29 | Count: 0 | Perimeter of the bean |\n",
    "| MajorAxisLength | float64 | Min: 183.60, Max: 738.86 | Mean: 320.14, Median: 296.88 | Std Dev: 85.69 | Count: 0 | Length of the major axis of the bean |\n",
    "| MinorAxisLength | float64 | Min: 122.51, Max: 460.20 | Mean: 202.27, Median: 192.43 | Std Dev: 44.97 | Count: 0 | Length of the minor axis of the bean |\n",
    "| AspectRation | float64 | Min: 1.02, Max: 2.43 | Mean: 1.58, Median: 1.55 | Std Dev: 0.25 | Count: 0 | Ratio of major axis to minor axis |\n",
    "| Eccentricity | float64 | Min: 0.22, Max: 0.91 | Mean: 0.75, Median: 0.76 | Std Dev: 0.09 | Count: 0 | Eccentricity of the ellipse |\n",
    "| ConvexArea | int64 | Min: -30, Max: 263261 | Mean: 53765.69, Median: 45178 | Std Dev: 29778.01 | Count: 0 | Convex hull area. Unusual negative minimum value |\n",
    "| Constantness | int64 | Min: 0, Max: 1 | Mean: 0.90, Median: 1 | Std Dev: 0.30 | Count: 0 | Binary feature |\n",
    "| EquivDiameter | float64 | Min: 0.16, Max: 3014441 | Mean: 476.25, Median: 238.44 | Std Dev: 25836.87 | Count: 0 | Extremely large range and high skewness (116.65) |\n",
    "| Colour | object | Unique values: brown, black, green, white | Mode: brown | N/A | Count: 6 | Categorical feature |\n",
    "| Extent | float64 | Min: 0.56, Max: 0.87 | Mean: 0.75, Median: 0.76 | Std Dev: 0.05 | Count: 6 | Ratio of area to bounding rectangle area |\n",
    "| Solidity | float64 | Min: 0.92, Max: 0.99 | Mean: 0.99, Median: 0.99 | Std Dev: 0.005 | Count: 0 | Ratio of area to convex hull area. Very narrow range |\n",
    "| roundness | float64 | Min: 0.49, Max: 0.99 | Mean: 0.87, Median: 0.88 | Std Dev: 0.06 | Count: 0 | Measure of how circular the bean is |\n",
    "| Compactness | float64 | Min: 0.64, Max: 0.99 | Mean: 0.80, Median: 0.80 | Std Dev: 0.06 | Count: 18 | Ratio of area to perimeter squared |\n",
    "| ShapeFactor1 | float64 | Min: 0.003, Max: 0.01 | Mean: 0.007, Median: 0.007 | Std Dev: 0.001 | Count: 0 | Shape descriptor |\n",
    "| ShapeFactor2 | float64 | Min: 0.0006, Max: 0.004 | Mean: 0.002, Median: 0.002 | Std Dev: 0.0006 | Count: 0 | Shape descriptor |\n",
    "| ShapeFactor3 | float64 | Min: 0.41, Max: 0.97 | Mean: 0.64, Median: 0.64 | Std Dev: 0.10 | Count: 0 | Shape descriptor |\n",
    "| ShapeFactor4 | float64 | Min: 0.70, Max: 3.97 | Mean: 2.37, Median: 2.37 | Std Dev: 0.87 | Count: 0 | Shape descriptor |\n",
    "| ShapeFactor5 | float64 | Min: 0.95, Max: 1.00 | Mean: 1.00, Median: 1.00 | Std Dev: 0.004 | Count: 0 | Shape descriptor |\n",
    "| ShapeFactor6 | float64 | Min: 0.0005, Max: 179.0 | Mean: 89.36, Median: 88.77 | Std Dev: 51.84 | Count: 5 | Shape descriptor. Wide range |\n",
    "| Class | object | Unique values: DERMASON, SIRA, SEKER, HOROZ, CALI, BARBUNYA, BOMBAY | Mode: DERMASON | N/A | Count: 17 | Target variable |\n",
    "| Sort order | float64 | Min: 0.00009, Max: 1.00 | Mean: 0.50, Median: 0.50 | Std Dev: 0.29 | Count: 0 | Purpose unclear, might be an artifact of data collection |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def enhance_feature_table(df):\n",
    "    def count_outliers(x):\n",
    "        if pd.api.types.is_numeric_dtype(x):\n",
    "            x_clean = x[x != '?'].astype(float)\n",
    "            q1, q3 = x_clean.quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - (1.5 * iqr)\n",
    "            upper_bound = q3 + (1.5 * iqr)\n",
    "            return ((x_clean < lower_bound) | (x_clean > upper_bound)).sum()\n",
    "        return 0  # Return 0 for non-numeric columns\n",
    "\n",
    "    def safe_agg(x, func):\n",
    "        try:\n",
    "            x_clean = x[x != '?']\n",
    "            return func(x_clean.astype(float)) if x_clean.dtype != 'object' else np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def get_range(x):\n",
    "        x_clean = x[x != '?']\n",
    "        if pd.api.types.is_numeric_dtype(x_clean):\n",
    "            return f\"{x_clean.astype(float).min()} - {x_clean.astype(float).max()}\"\n",
    "        else:\n",
    "            return f\"{x_clean.nunique()} unique values\"\n",
    "\n",
    "    def get_central_tendency(x):\n",
    "        x_clean = x[x != '?']\n",
    "        if pd.api.types.is_numeric_dtype(x_clean):\n",
    "            return f\"Mean: {x_clean.astype(float).mean():.2f}, Median: {x_clean.astype(float).median():.2f}\"\n",
    "        else:\n",
    "            return f\"Mode: {x_clean.mode().iloc[0] if not x_clean.mode().empty else 'N/A'}\"\n",
    "\n",
    "    def get_dispersion(x):\n",
    "        x_clean = x[x != '?']\n",
    "        if pd.api.types.is_numeric_dtype(x_clean):\n",
    "            return f\"Std Dev: {x_clean.astype(float).std():.2f}, IQR: {x_clean.astype(float).quantile(0.75) - x_clean.astype(float).quantile(0.25):.2f}\"\n",
    "        else:\n",
    "            return \"N/A\"\n",
    "\n",
    "    def get_distribution(x):\n",
    "        x_clean = x[x != '?']\n",
    "        if pd.api.types.is_numeric_dtype(x_clean):\n",
    "            return f\"Skew: {safe_agg(x_clean, stats.skew):.2f}, Kurtosis: {safe_agg(x_clean, stats.kurtosis):.2f}\"\n",
    "        else:\n",
    "            return \"N/A\"\n",
    "\n",
    "    table = pd.DataFrame({\n",
    "        'Data Type': df.dtypes,\n",
    "        'Range': df.apply(get_range),\n",
    "        'Central Tendency': df.apply(get_central_tendency),\n",
    "        'Dispersion': df.apply(get_dispersion),\n",
    "        'Missing Values': df.apply(lambda x: (x == '?').sum()).apply(lambda x: f\"{x} ({x/len(df)*100:.1f}%)\"),\n",
    "        'Unique Values': df.apply(lambda x: x[x != '?'].nunique()),\n",
    "        'Distribution': df.apply(get_distribution),\n",
    "        'Outliers': df.apply(count_outliers).apply(lambda x: f\"{x} ({x/len(df)*100:.1f}%)\"),\n",
    "    })\n",
    "\n",
    "    def get_concerns(column):\n",
    "        concerns = []\n",
    "        x_clean = column[column != '?']\n",
    "        if pd.api.types.is_numeric_dtype(x_clean):\n",
    "            if x_clean.astype(float).min() < 0:\n",
    "                concerns.append(\"Contains negative values\")\n",
    "            if np.abs(safe_agg(x_clean, stats.skew)) > 2:\n",
    "                concerns.append(\"Highly skewed\")\n",
    "            if x_clean.nunique() == 1:\n",
    "                concerns.append(\"No variation (constant)\")\n",
    "        elif pd.api.types.is_string_dtype(x_clean):\n",
    "            if x_clean.str.contains(r'[^a-zA-Z\\s]').any():\n",
    "                concerns.append(\"Contains non-alphabetic characters\")\n",
    "        if (column == '?').sum() > 0:\n",
    "            concerns.append(f\"Contains missing values ('?')\")\n",
    "        return ', '.join(concerns) if concerns else \"None detected\"\n",
    "\n",
    "    table['Data Quality Concerns'] = df.apply(get_concerns)\n",
    "\n",
    "    # Add correlation information only for numeric columns\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    numeric_df = numeric_df.apply(lambda x: pd.to_numeric(x.replace('?', np.nan), errors='coerce'))\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    high_corr = (corr_matrix.abs() > 0.9) & (corr_matrix != 1.0)\n",
    "    table['High Correlations'] = [', '.join(high_corr.index[high_corr[col]].tolist()) if col in high_corr.index else 'N/A' for col in df.columns]\n",
    "\n",
    "    return table\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "enhanced_table = enhance_feature_table(df)\n",
    "\n",
    "enhanced_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential improvements or areas to consider:\n",
    "\n",
    "1. Extent, Compactness, and ShapeFactor6 are identified as 'object' type but seem to contain numeric data. You might want to investigate why these weren't converted to numeric types.\n",
    "2. The 'Constantness' feature has only two unique values (0 and 1). Consider if this should be treated as a binary categorical variable instead of a numeric one.\n",
    "3. The 'ConvexArea' feature has negative values, which seems unusual for an area measurement. This might need further investigation.\n",
    "4. The 'EquivDiameter' has an extremely large range and high skewness. You might want to look into this feature more closely to understand if there are data quality issues.\n",
    "5. For categorical variables like 'Colour' and 'Class', it might be helpful to include the frequency distribution of each category.\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "1. Investigate the features identified as 'object' type that appear to be numeric (Extent, Compactness, ShapeFactor6).\n",
    "2. Look into the negative values in 'ConvexArea' and the extreme values in 'EquivDiameter'.\n",
    "3. Consider adding category frequencies for categorical variables.\n",
    "4. Use this table to guide your data preprocessing steps and feature selection for model development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
